{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7629570e-533f-4e14-894a-ecc3e24e76cd",
   "metadata": {},
   "source": [
    "# ML Modeling\n",
    "This notebook outlines a method for constructing an ensemble of **Random Forest Classifiers** using **Bayesian optimization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1789ba-57e6-4017-9a99-292d4a497b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import math\n",
    "import warnings\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466785f9-46cf-4812-8f7d-3fcf584e9d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef068c46-9264-4b4f-a8e7-a6ad6cac12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2779fc52-336b-4870-9c3a-c4760239da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt import gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0548256-a496-45c3-a998-5da75e88c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ecosystem_classifier.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from ecosystem_classifier import EcosystemClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1261b9e5-c73c-488e-b96a-af11f37a7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer_start = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e21c5f0-bef5-4b46-9dac-ba810f51d440",
   "metadata": {},
   "source": [
    "We begin by importing the preprocessed DataFrame containing the dataset (see **data_preprocessing.jpynb**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb5db8f8-3736-44fe-85d6-3e01d5394e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(filepath_or_buffer=\"dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e159771-cdae-4fec-af89-524074542773",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, nr_columns = df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641cf252-f4a7-4f89-87cf-2c61aecce96d",
   "metadata": {},
   "source": [
    "## Building the Variables Vector Space \n",
    "We commence by partitioning the independent variable $x$ from the target variable $y$, following which we divide the dataset into training and testing subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e06665-69e7-4fbf-b533-e4009bb88eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(labels=\"y\",\n",
    "            axis=1)\n",
    "y = df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "308ff887-db35-4693-8134-400ad2f51f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                    test_size=.2,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98ca28f-5972-495f-b798-6fb0cd37e5ab",
   "metadata": {},
   "source": [
    "We construct a dictionary that associates variable names with their permissible values. Subsequently, we establish the vector space within which the optimization process will unfold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55140e3c-e842-4da1-9870-d9f162625e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = {0: \"gini\", \n",
    "             1: \"entropy\", \n",
    "             2: \"log_loss\"}\n",
    "max_features = {0: \"sqrt\",\n",
    "                1: \"log2\",\n",
    "                2: None}\n",
    "class_weight = {0: \"balanced\",\n",
    "                1: None}\n",
    "\n",
    "variables_dict = {\"criterion\": criterion,\n",
    "                  \"max_features\": max_features, \n",
    "                  \"class_weight\": class_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d066b50-bf7b-4f55-bc69-3a0103216886",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [Integer(low=0,\n",
    "                 high=2,\n",
    "                 name=\"criterion\"),\n",
    "        Integer(low=2, \n",
    "                high=nr_columns,\n",
    "                name=\"max_depth\"), \n",
    "        Integer(low=0, \n",
    "                high=2, \n",
    "                name=\"max_features\"), \n",
    "        Integer(low=0, \n",
    "                high=1, \n",
    "                name=\"class_weight\"),\n",
    "        Real(low=.01, \n",
    "             high=1, \n",
    "             name=\"max_samples\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9714efb-0739-4d3d-a084-803194444d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, nr_columns, x, y, class_weight, criterion, max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc59afb-2aa4-4d24-9010-7a9533a70254",
   "metadata": {},
   "source": [
    "## Building the Ecosystem Model\n",
    "The **build_ecosystem** function constructs an ensemble of Random Forest Classifiers (an Ecosystem Classifier) optimized through Bayesian optimization. It begins by defining an objective function that computes the loss to be minimized during optimization. This function is then optimized using Bayesian optimization techniques, iterating over a specified number of optimization runs. The chosen loss function aims to maximize the **Recall Score** via cross validation. Since the main focus consists in optimizing the **True** outputs, a Macro averaging is chosen for the Recall.\n",
    "\n",
    "During each optimization run, a Random Forest classifier is trained with hyperparameters sampled from the variables vector space. The best-performing models from each optimization run are stored. Finally, the top-performing models are selected based on their cross validation scores, which will serve as weights, and an instance of EcosystemClassifier is built, encapsulating the selected models and their weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54f191d3-f43e-4b6d-a266-d0732e73a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ecosystem(x: np.array,\n",
    "                    y: np.array,\n",
    "                    space: any,\n",
    "                    variables: dict,\n",
    "                    nr_calls: int = 10,\n",
    "                    nr_forests: int = 1\n",
    "                    ) -> EcosystemClassifier:\n",
    "    \"\"\"\n",
    "    Build ecosystem consisting of Random Forest Classifiers whose parameters have been tuned via Bayesian optimization using Gaussian Processes to optimize macro recall.\n",
    "    :param x: Variables.\n",
    "    :param y: Target.\n",
    "    :param space: Vector space that x belongs to.\n",
    "    :param variables: Dictionary mapping variable names to variables_dictionaries.\n",
    "    :param nr_calls: Nr. of calls of the objective function.\n",
    "    :param nr_forests: Nr. of Random Forest Classifiers constituting the ecosystem.\n",
    "    :return: DataFrame containing the top sqrt(nr_forests) performing models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def objective_function(params: list\n",
    "                           ) -> float:\n",
    "        \"\"\"\n",
    "        Loss function to be optimized by the Bayesian optimization.\n",
    "        :param params: list of parameters belonging to the vector space 'space'.\n",
    "        :return: Loss.\n",
    "        \"\"\"\n",
    "        params_value = {}\n",
    "        for count, param in enumerate(space):\n",
    "            name = param.name\n",
    "            params_value[name] = params[count] if name not in variables\\\n",
    "                                 else variables[name][params[count]]\n",
    "            \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                            test_size=.2,\n",
    "                                                            stratify=y)\n",
    "        \n",
    "        random_forest = RandomForestClassifier()\n",
    "        random_forest.set_params(**params_value)\n",
    "        random_forest.fit(x_train, y_train)\n",
    "        model_list.append(random_forest)\n",
    "        \n",
    "        return -f1_score(y_true=y_test,\n",
    "                         y_pred=random_forest.predict(x_test),\n",
    "                         average=\"macro\")\n",
    "\n",
    "    result_list = {}\n",
    "    for count in range(nr_forests):\n",
    "        model_list = []\n",
    "        result = gp_minimize(func=objective_function,\n",
    "                             dimensions=space, \n",
    "                             n_calls=nr_calls)\n",
    "        result_list[f\"forest.{count}\"] = (-result.fun,\n",
    "                                          model_list[np.argmin(result.func_vals)],\n",
    "                                          result)\n",
    "        \n",
    "    df = pd.DataFrame(data=result_list).T\n",
    "    df.rename(columns = {0: \"weight\",\n",
    "                         1: \"model\",\n",
    "                         2: \"report\"},\n",
    "              inplace=True)\n",
    "    df.sort_values(by=\"weight\",\n",
    "                   ascending=False,\n",
    "                   inplace=True)\n",
    "    df = df.head(math.floor(math.sqrt(nr_forests)))\n",
    "    \n",
    "    return EcosystemClassifier(weights=df.weight,\n",
    "                               models=df.model, \n",
    "                               reports=df.report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22267c59-983b-410e-8f5c-aa6fad8655df",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\",\n",
    "                        category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1c81c27-6592-4a1c-9619-b211d3b3a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecosystem = build_ecosystem(x=x_train,\n",
    "                            y=y_train, \n",
    "                            space=space,\n",
    "                            variables=variables_dict,\n",
    "                            nr_calls=60,\n",
    "                            nr_forests=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a3bff-01eb-4920-b4af-183e9a7942c8",
   "metadata": {},
   "source": [
    "Finally, we export and store the results obtained by the Ecosystem Classifier in binary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fa4b803-6c1c-46d0-8374-aa651e25c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"y_true\",\n",
    "                           \"y_pred\",\n",
    "                           \"y_prob\"])\n",
    "df.y_true, df.y_pred, df.y_prob = y_test.values, ecosystem.predict(x_test), ecosystem.predict_proba(x_test)\n",
    "\n",
    "test = {\"df\": df,\n",
    "        \"feature_importance\": ecosystem.feature_importance(feature_names=x_train.columns), \n",
    "        \"loss_eval\": np.array([report.func_vals for report in ecosystem.reports])}\n",
    "\n",
    "with open(file=\"test_results.pkl\",\n",
    "          mode=\"wb\") as results:\n",
    "    pkl.dump(obj=test,\n",
    "             file=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a89c35e-97f0-4c68-80eb-69c94f14efc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time of the script:  4.37h\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total running time of the script: {(time() - timer_start) / 3600: .2f}h\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
